{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from ev_parser import gesture_parser\n",
    "from functools import partial\n",
    "from scipy import interpolate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "%matplotlib inline\n",
    "\n",
    "path_out = 'C:/skoltech_hand_writing'\n",
    "subj = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SCRIPT \"4_File.ipynb\"\n",
    "def find_peaks(array_, koef=1.1, max_flg=False, mean=0, std=0 , custom_mean_flg=False):\n",
    "    \n",
    "    mean_=np.mean(array_)\n",
    "    std_=np.std(array_)\n",
    "    \n",
    "    if custom_mean_flg:\n",
    "        mean_=mean\n",
    "        std_=std\n",
    "\n",
    "    max_=mean_+koef*std_\n",
    "    min_=mean_-koef*std_\n",
    "    \n",
    "    \n",
    "    \n",
    "    max_array_=[max_]*len(array_)\n",
    "    min_array_=[min_]*len(array_)\n",
    "    \n",
    "    \n",
    "    print(max_)\n",
    "    inds=np.where(array_>max_)[0]\n",
    "    \n",
    "    if max_flg:\n",
    "        return inds, max_\n",
    "    \n",
    "    else:\n",
    "        return inds\n",
    "\n",
    "def reduce_peaks(marks_array_inds,  threhold, with_log=False,):\n",
    "    \n",
    "    new_marks_array_inds=[marks_array_inds[0]]\n",
    "    for i in range(1,len(marks_array_inds)):\n",
    "        if marks_array_inds[i]-new_marks_array_inds[-1]<threhold:\n",
    "            if with_log:\n",
    "                print(i)\n",
    "        else:\n",
    "            new_marks_array_inds.append(marks_array_inds[i])\n",
    "\n",
    "    return new_marks_array_inds\n",
    "\n",
    "def reject_list_by_sigma_2(epochs_1):\n",
    "\n",
    "    data_epochs_1=epochs_1.get_data()\n",
    "    mean_=np.mean(data_epochs_1,(0,2))\n",
    "    std_=np.std(data_epochs_1,(0,2))\n",
    "\n",
    "    max_=(mean_+7*std_)\n",
    "    min_=(mean_-7*std_)\n",
    "\n",
    "\n",
    "\n",
    "    axx=data_epochs_1.shape[0]\n",
    "    axx2=data_epochs_1.shape[2]\n",
    "    rej=[]\n",
    "\n",
    "    for i in range(axx):\n",
    "        for j in range(axx2):\n",
    "            if np.sum(max_-data_epochs_1[i,:,j]<0)!=0 or np.sum(min_-data_epochs_1[i,:,j]>0)!=0:\n",
    "                  rej.append(i)\n",
    "\n",
    "        reject_list=np.unique(rej).tolist()\n",
    "    return reject_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes=np.arange(1, 6)\n",
    "\n",
    "handwriting=[]\n",
    "eeg=[]\n",
    "marks=[]\n",
    "sensor=[]\n",
    "sess=[]\n",
    "\n",
    "sh_list = []\n",
    "for code in codes:\n",
    "    events_2_3 = np.loadtxt(f'{path_out}/hand_writing/{subj}/epochs/Rec_{code}/events_2-3_tablet_data.csv')\n",
    "                           \n",
    "\n",
    "    # CHECK THE TIME CONSTANT IN THE FOLLOWING LINE\n",
    "    sh = (events_2_3[events_2_3[:, 2]==-3][:, 0] - events_2_3[events_2_3[:, 2]==-2][:, 0]) < 2.5 * 2048.0\n",
    "    sh_list = np.concatenate([sh_list, sh])\n",
    "\n",
    "    # TAKE FROM THE [1:] EPOCH! BECAUSE THERE IS NO MARK FOR THE FIRST ONE!\n",
    "    # ALSO LOOK AT THE SESS::: sess.append(...).iloc[1:] !!! also taken from the second one!!!!\n",
    "\n",
    "    e1=mne.read_epochs(f'{path_out}/hand_writing/{subj}/epochs/Rec_{code}/epochs_handwriting_tablet-epo.fif', verbose = False)\n",
    "    e2=mne.read_epochs(f'{path_out}/hand_writing/{subj}/epochs/Rec_{code}/epochs-long-epo.fif', verbose = False)#[1:]\n",
    "    e3=mne.read_epochs(f'{path_out}/hand_writing/{subj}/epochs/Rec_{code}/epochs-marks-long-epo.fif', verbose = False)#[1:]\n",
    "    e4=e3.copy().drop_channels(['C'])\n",
    "    e4._data = e3._data[:, 0, None, :]\n",
    "    e4._data = e3._data[:, 1, None, :]\n",
    "    print(f'HANDWRITING EPOCHS: {len(e1)}')\n",
    "    print(f'EPOCHS: {len(e2)}')\n",
    "    print(f'MARKS: {len(e3)}')    \n",
    "    sess.append(pd.read_excel(f'8_Sessions/Digits_Tyumen_{code}.xlsx').iloc[1:] )\n",
    "\n",
    "    handwriting.append(e1)\n",
    "    eeg.append(e2)\n",
    "    marks.append(e3)\n",
    "    sensor.append(e4)\n",
    "\n",
    "sess_df=pd.concat(sess).reset_index()[['Digit_text']]\n",
    "print(sess_df.shape, sess_df.shape[0] / 5)\n",
    "sess_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks_all=mne.concatenate_epochs(marks)\n",
    "sensor_all=mne.concatenate_epochs(sensor)\n",
    "eeg_all=mne.concatenate_epochs(eeg)\n",
    "handwriting_all=mne.concatenate_epochs(handwriting)\n",
    "\n",
    "# drop epocs based on signal dispersion\n",
    "drop_list=reject_list_by_sigma_2(eeg_all)\n",
    "\n",
    "marks_all.drop(drop_list)\n",
    "sensor_all.drop(drop_list)\n",
    "eeg_all.drop(drop_list)\n",
    "handwriting_all.drop(drop_list)\n",
    "sess_df=sess_df.drop(drop_list, axis=0).reset_index()[['Digit_text']]\n",
    "sh_list = np.delete(sh_list, drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_num=len(eeg_all)\n",
    "epochs_duration=eeg_all._data.shape[-1]\n",
    "\n",
    "ss=StandardScaler()\n",
    "\n",
    "marks_data=np.squeeze(marks_all._data[:,1,:])\n",
    "marks_data_sq=marks_data*10\n",
    "marks_data_sc=ss.fit_transform(marks_data.flatten().reshape(-1,1)).reshape(epochs_num,epochs_duration)\n",
    "\n",
    "print(marks_data.shape, marks_data_sc.shape)\n",
    "\n",
    "marks_data_sc=marks_data_sc.reshape(epochs_num,1,epochs_duration)\n",
    "sensor_all._data=marks_data_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop epochs based on trial length\n",
    "new_drop_list = np.where(sh_list == 0)[0]\n",
    "marks_all.drop(new_drop_list)\n",
    "sensor_all.drop(new_drop_list)\n",
    "eeg_all.drop(new_drop_list)\n",
    "handwriting_all.drop(new_drop_list)\n",
    "sess_df=sess_df.drop(new_drop_list, axis=0).reset_index()[['Digit_text']]\n",
    "\n",
    "sess_df.to_csv(f'{path_out}/hand_writing/{subj}/Digits_trials_final_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_peaks(array_, koef=1.5, max_flg=False, mean=0, std=0 , custom_mean_flg=False):\n",
    "    \n",
    "    mean_=np.mean(array_)\n",
    "    std_=np.std(array_)\n",
    "    \n",
    "    if custom_mean_flg:\n",
    "        mean_=mean\n",
    "        std_=std\n",
    "\n",
    "    max_=mean_+koef*std_\n",
    "    \n",
    "    print(max_)\n",
    "    inds=np.where(array_>max_)[0]\n",
    "    \n",
    "    if max_flg:\n",
    "        return inds, max_\n",
    "    \n",
    "    else:\n",
    "        return inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot averaged marks and sensor data to check the alignment\n",
    "os.makedirs(f'{path_out}/hand_writing/{subj}/output', exist_ok=True)\n",
    "\n",
    "mean=np.average(marks_all._data,0)\n",
    "mean_B=mean[0]\n",
    "mean_C=mean[1]\n",
    "\n",
    "plt.plot(mean_B, label = 'channel B')\n",
    "plt.plot(mean_C, label = 'channel C')\n",
    "plt.legend()\n",
    "plt.savefig(f'{path_out}/hand_writing/{subj}/output/channels BC.png', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ERP for each channel\n",
    "for i in eeg_all.ch_names:\n",
    "    ind=eeg_all.ch_names.index(i)\n",
    "    fig = eeg_all.plot_image([ind])\n",
    "    fig[0].savefig(f'{path_out}/hand_writing/{subj}/output/{i}.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \"ERP\" of sensor channel\n",
    "fig = sensor_all.copy().crop(-2,4).plot_image([0])\n",
    "fig[0].savefig(f'{path_out}/hand_writing/{subj}/output/sensor.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \"ERP\" of marks channel\n",
    "fig = marks_all.copy().crop(-2,4).plot_image([0])\n",
    "fig[0].savefig(f'{path_out}/hand_writing/{subj}/output/marks.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot point whithin each epoch, where the actual drawing started based on the sensor recordings\n",
    "%matplotlib inline\n",
    "mean=np.average(marks_data,0)\n",
    "mean_sq=np.average(marks_data_sq,0)\n",
    "mean_sc=np.average(marks_data_sc,0)\n",
    "\n",
    "print(mean.shape,mean_sq.shape)\n",
    "\n",
    "plt.plot(mean)\n",
    "plt.plot(mean_sq)\n",
    "plt.plot(mean_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
